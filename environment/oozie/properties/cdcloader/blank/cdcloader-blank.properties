#############################################################
# Cluster Properties
#############################################################
#The URL of the job tracker (e,g. bda.kainos.com:8032)
cluster.config.jobtracker= 
#The HDFS namespace to use (e.g. namespace1:8020)
cluster.config.namespace= 
# The mapreduce queue name (use default)
cluster.config.queuename=default
#############################################################
# HDFS PATHS
#############################################################

# Data
#The cdc hdfs base directory (e.g. /etl/cdc/) 
hdfa.paths.data.prefix=
# A fully qualified path to the data base dir
hdfs.paths.data.root=${cluster.config.namespace}${hdfa.paths.data.prefix}
#The name of the processing directory
hdfs.paths.data.processing= 
#The name of the output directory
hdfs.paths.data.output=
#The name of the archive directory
hdfs.paths.data.archive=
#The name of the error directory
hdfs.paths.data.error=

#Control
# The base dir for control table data
hdfa.paths.control.prefix=
# A fully qualified path to the control base dir
hdfs.paths.control.root=${cluster.config.namespace}${hdfa.paths.data.prefix}
#The name of the output dir for control data
hdfs.paths.control.output= 
#The name of the temp dir for control data
hdfs.paths.control.temp=

#############################################################
# Spark Properties
#############################################################
# the spark master
spark.master=yarn
#Spark mode (client/cluster)
spark.mode=cluster
#The path to the spark jar
spark.jar.location=
#Additional spark options (executors, memory etc.)
spark.options=

#############################################################
# CDC Spark Properties
#############################################################
# Separate listed values with an underscore.  Ie 1_2_3_4
#############################################################

#Loader
#The name of the attunity change mask column 
spark.cdcloader.columns.attunity.name.changemask= 
#The name of the change operation column 
spark.cdcloader.columns.attunity.name.changeoperation= 
#The name of the attunity change sequence column 
spark.cdcloader.columns.attunity.name.changesequence= 
#A list of column names in the control table 
spark.cdcloader.columns.control.names.controlcolumnnames= 
#The value of the delete operation in the attunity change operation field
spark.cdcloader.columns.attunity.value.changeoperation= 
#The name to give the isDeleted attribute in the outputted avro 
spark.cdcloader.columns.metadata.name.isdeleted= 
#The suffix given to attunity change tables (e.g. __ct) 
spark.cdcloader.control.attunity.changetablesuffix= 
#The name to give the load timestamp attribute in the outputted avro 
spark.cdcloader.columns.metadata.name.loadtimestamp= 
#The timestamp format for the attunity change sequence 
spark.cdcloader.format.timestamp.attunity= 
#The timestamp format to use for hive 
spark.cdcloader.format.timestamp.hive= 
#The input base directory (e.g. /etl/cdc/attunity/ndex/) 
spark.cdcloader.path.data.basedir= 
#The path to the control table 
spark.cdcloader.path.data.control= 
#The path to the output directory (e.g. /etl/cdc/cdcloader/ndex/) 
spark.cdcloader.path.data.outputbasedir= 
#the name of the folder to write to (e.g. processing 
spark.cdcloader.path.data.outdir= 
#The base directory for sql queries (e.g. /metadata/cdcloader/hive/queries/ndex/ 
spark.cdcloader.path.sql.basedir= 
#The path to the control table sql (e.g. /metadata/cdcloader/hive/queries/control/)
spark.cdcloader.path.sql.control= 
#The name of the control table  
spark.cdcloader.tables.control.names= 
#Should the change mask be enabled(true/false)?
spark.cdcloader.control.changemask.enabled= 
#An '_' separated list of tables to process  
spark.cdcloader.input.tablenames= 
 
# The following properties are required per input table: 
# spark.cdcloader.control.columnpositions 
#  - A list of ordinal column positions in the *change table*
#    e.g. spark.cdcloader.control.columnpositionstablename.policy 
# spark.cdcloader.columns.control.name.tablename 
# - The name of the table name field in the control table 
#   e.g. spark.cdcloader.columns.control.name.tablename.policy 

# spark.cdcloader.control.columnpositions.
# spark.cdcloader.columns.control.name.


#Control
#The path to the file containing the sql statement for the control processor.
spark.cdccontrol.path.sql=
#The path to the control table
spark.cdccontrol.path.data.control.input=
#The path to write control data to
spark.cdccontrol.path.data.control.output=
#The path to the data to be parsed
spark.cdccontrol.path.data.input=
#The name of the control table
spark.cdccontrol.tables.control.name=
# The name of the temp table used while processing.
spark.cdccontrol.tables.temp.name=

#############################################################
# CDC Oozie Properties
#############################################################

#Loader
#The name of the source being processed
cdc.loader.source.name=
#The name of the loader spark jov
cdc.loader.job.name=cdcloader-${cdc.loader.source.name}
#The fully qualified path to the main cdcloader class
cdc.loader.class.main=enstar.globaldatahub.cdcloader.CDCLoaderJob
#Fixed properties for CDCloader class, populated from spark.cdcloader.* above
cdc.loader.options.fixed= 'spark.cdcloader.columns.attunity.name.changemask=${spark.cdcloader.columns.attunity.name.changemask},spark.cdcloader.columns.attunity.name.changeoperation=${spark.cdcloader.columns.attunity.name.changeoperation},spark.cdcloader.columns.attunity.name.changesequence=${spark.cdcloader.columns.attunity.name.changesequence},spark.cdcloader.columns.control.names.controlcolumnnames=${spark.cdcloader.columns.control.names.controlcolumnnames},spark.cdcloader.columns.attunity.value.changeoperation=${spark.cdcloader.columns.attunity.value.changeoperation},spark.cdcloader.columns.metadata.name.isdeleted=${spark.cdcloader.columns.metadata.name.isdeleted},spark.cdcloader.control.attunity.changetablesuffix=${spark.cdcloader.control.attunity.changetablesuffix},spark.cdcloader.columns.metadata.name.loadtimestamp=${spark.cdcloader.columns.metadata.name.loadtimestamp},spark.cdcloader.format.timestamp.attunity=${spark.cdcloader.format.timestamp.attunity},spark.cdcloader.format.timestamp.hive=${spark.cdcloader.format.timestamp.hive},spark.cdcloader.path.data.basedir=${spark.cdcloader.path.data.basedir},spark.cdcloader.path.data.control=${spark.cdcloader.path.data.control},spark.cdcloader.path.data.outputbasedir=${spark.cdcloader.path.data.outputbasedir},spark.cdcloader.path.data.outdir=${spark.cdcloader.path.data.outdir},spark.cdcloader.path.sql.basedir=${spark.cdcloader.path.sql.basedir},spark.cdcloader.path.sql.control=${spark.cdcloader.path.sql.control},spark.cdcloader.tables.control.names=${spark.cdcloader.tables.control.names},spark.cdcloader.control.changemask.enabled=${spark.cdcloader.control.changemask.enabled},spark.cdcloader.input.tablenames=${spark.cdcloader.input.tablenames}'
#Dynamic (per table) properties, set above 
#use k=v,k=v to populate as per fixed properties.
cdc.loader.options.dynamic= 
#command line options 
cdc.loader.options= ${cdc.loader.options.fixed}${cdc.loader.options.dynamic}

#Control
#The spark job name
cdc.control.job.name= cdccontrol-${cdc.loader.source.name}
#The fully qyuualified path to the main CDC control class
cdc.control.main.class=enstar.globaldatahub.cdccontrol.CDCControlJob
#Command line options for cdc control
cdc.control.options='spark.cdccontrol.path.sql=${spark.cdccontrol.path.sql},spark.cdccontrol.path.data.control.input=${spark.cdccontrol.path.data.control.input},spark.cdccontrol.path.data.control.output=${spark.cdccontrol.path.data.control.output},spark.cdccontrol.path.data.input=${spark.cdccontrol.path.data.input},spark.cdccontrol.tables.control.name=${spark.cdccontrol.tables.control.name},spark.cdccontrol.tables.temp.name=${spark.cdccontrol.tables.temp.name}'

#############################################################
# Oozie Properties
#############################################################
#The oozie job name
oozie.job.name = cdcLoader-${cdc.loader.source.name}

oozie.root=${cluster.config.namespace}/app/oozie/cdc/cdcloader/
#The path to the oozie workflow (enable to use without co-ordinator)
#oozie.wf.application.path=${oozie.root}/workflow.xml
oozie.application.path=${oozie.root}/workflow.xml
#The path to the oozie co-ordinator
oozie.coord.application.path=${oozie.root}/coordinator.xml
#How often should the coordinator run (cron format)
oozie.coordinator.frequency=*/15 * * * *
#The start time for the oozie co-ordinator
oozie.coordinator.starttime=InvalidSeeReadme
#Use the oozie sharelib
oozie.use.system.libpath=true
